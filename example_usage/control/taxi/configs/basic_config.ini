[ENVIRONMENT]
env = Taxi-v3

[POPULATION]
population = None
policy_network_class = DiscreteActionMLPPolicy
policy_network_creator_fn = None
feature_constructor = None

[EVOLUTION]
mu = 150
lambda = 1000
parent_selection_fn = random
mutation_mean = 0.0
mutation_std = 0.1
update_mutation_std = False
mutation_std_min = 0.01
mutation_std_max = 0.1
ema_elite_weight = 0.9
stagnation_patience = 5
stopping_score = None
agent_name_prefix = evo_
num_generations_to_run = 100

[TRAJECTORY]
curate_trajectory = True
curate_elite_states = True
log_random_k_score = True

[REPLAY_BUFFER]
replay_buffer_capacity = 500
replay_buffer_minimum_size = 100

[Q_LEARNING]
q_network = None
q_network_preferred_device = None
q_learner = None
q_step_size = 0.001
q_discount_factor = 0.99
q_learner_num_steps = 1000
q_learner_target_network_update_frequency = 1000
q_learner_batch_size = 32
train_q_learner = True
num_individuals_to_train_q_fn = 10
selection_fn_to_train_q_fn = random

[SELECTION_AND_EVALUATION]
num_top_k = 25
num_elites = 5
score_evaluation_num_episodes = 10
fitness_evaluation_num_samples = 100
reevaluate_agent_score = False
evaluate_q_derived_policy = True

[LOGGING]
write_summary = True
summary_dir = None
render = False


